{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a6544ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b167ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    latitude  longitude  available  capacity  total  capacity_num   cpu_num  \\\n",
      "0  28.568238  77.219666        0.0      15.0    2.0          15.0  4.126608   \n",
      "1  28.541995  77.260583        0.0       3.0    3.0           3.3  4.126608   \n",
      "2  28.571189  77.259806        0.0      15.0    2.0          15.0  4.126608   \n",
      "3  28.588991  77.253240        0.0      15.0    4.0          15.0  4.126608   \n",
      "4  28.549427  77.254636        0.0      15.0    1.0          15.0  4.126608   \n",
      "\n",
      "   supports_4w  supports_2w  n_vehicle_types  ...  vendor_name_Powerbank  \\\n",
      "0         True        False                1  ...                  False   \n",
      "1         True         True                3  ...                  False   \n",
      "2         True        False                1  ...                  False   \n",
      "3         True        False                1  ...                  False   \n",
      "4         True        False                1  ...                  False   \n",
      "\n",
      "   vendor_name_Pvt. Ltd.  vendor_name_REIL  vendor_name_REVOS  \\\n",
      "0                  False             False              False   \n",
      "1                  False              True              False   \n",
      "2                  False              True              False   \n",
      "3                  False              True              False   \n",
      "4                  False             False              False   \n",
      "\n",
      "   vendor_name_Smart E  vendor_name_Sun Mobility  vendor_name_TPDDL  \\\n",
      "0                False                     False              False   \n",
      "1                False                     False              False   \n",
      "2                False                     False              False   \n",
      "3                False                     False              False   \n",
      "4                False                     False              False   \n",
      "\n",
      "   vendor_name_Verdemobility  station_type_charging  power_type_DC  \n",
      "0                      False                   True           True  \n",
      "1                      False                   True          False  \n",
      "2                      False                   True           True  \n",
      "3                      False                   True           True  \n",
      "4                      False                   True           True  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2705 entries, 0 to 2704\n",
      "Data columns (total 32 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   latitude                            2705 non-null   float64\n",
      " 1   longitude                           2705 non-null   float64\n",
      " 2   available                           2705 non-null   float64\n",
      " 3   capacity                            2705 non-null   float64\n",
      " 4   total                               2705 non-null   float64\n",
      " 5   capacity_num                        2705 non-null   float64\n",
      " 6   cpu_num                             2705 non-null   float64\n",
      " 7   supports_4w                         2705 non-null   bool   \n",
      " 8   supports_2w                         2705 non-null   bool   \n",
      " 9   n_vehicle_types                     2705 non-null   int64  \n",
      " 10  vendor_name_BSES                    2705 non-null   bool   \n",
      " 11  vendor_name_BatterySmart            2705 non-null   bool   \n",
      " 12  vendor_name_BluSmart                2705 non-null   bool   \n",
      " 13  vendor_name_E-Fill Electric         2705 non-null   bool   \n",
      " 14  vendor_name_EEE                     2705 non-null   bool   \n",
      " 15  vendor_name_EESL                    2705 non-null   bool   \n",
      " 16  vendor_name_ElectriVa               2705 non-null   bool   \n",
      " 17  vendor_name_GensolCharge Pvt. Ltd.  2705 non-null   bool   \n",
      " 18  vendor_name_HPCL                    2705 non-null   bool   \n",
      " 19  vendor_name_JBM Renewables          2705 non-null   bool   \n",
      " 20  vendor_name_Jio-bp                  2705 non-null   bool   \n",
      " 21  vendor_name_PlugNgo                 2705 non-null   bool   \n",
      " 22  vendor_name_Powerbank               2705 non-null   bool   \n",
      " 23  vendor_name_Pvt. Ltd.               2705 non-null   bool   \n",
      " 24  vendor_name_REIL                    2705 non-null   bool   \n",
      " 25  vendor_name_REVOS                   2705 non-null   bool   \n",
      " 26  vendor_name_Smart E                 2705 non-null   bool   \n",
      " 27  vendor_name_Sun Mobility            2705 non-null   bool   \n",
      " 28  vendor_name_TPDDL                   2705 non-null   bool   \n",
      " 29  vendor_name_Verdemobility           2705 non-null   bool   \n",
      " 30  station_type_charging               2705 non-null   bool   \n",
      " 31  power_type_DC                       2705 non-null   bool   \n",
      "dtypes: bool(24), float64(7), int64(1)\n",
      "memory usage: 232.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset from the 'data' directory\n",
    "data = pd.read_csv('../data/cleaned_data.csv')\n",
    "\n",
    "# Display the first few rows to confirm it loaded correctly\n",
    "print(data.head())\n",
    "\n",
    "# Get the list of columns to verify the cleaning\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db59eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target variable and any other columns you don't want to use as features\n",
    "X = data.drop('power_type_DC', axis=1)\n",
    "# The target variable you want to predict\n",
    "y = data['power_type_DC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af38049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c748300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.95\n",
      "Precision: 0.77\n",
      "Recall: 0.98\n",
      "F1-Score: 0.86\n",
      "\n",
      "Confusion Matrix:\n",
      "[[437  23]\n",
      " [  2  79]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize and train a Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6d8fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Separate numeric and categorical column names\n",
    "numeric_features = ['latitude', 'longitude', 'available', 'capacity', 'total', 'capacity_num', 'cpu_num', 'n_vehicle_types']\n",
    "categorical_features = ['supports_4w', 'supports_2w', 'vendor_name_BSES', 'vendor_name_BatterySmart',\n",
    "                      'vendor_name_BluSmart', 'vendor_name_E-Fill Electric', 'vendor_name_EEE',\n",
    "                      'vendor_name_EESL', 'vendor_name_ElectriVa', 'vendor_name_GensolCharge Pvt. Ltd.',\n",
    "                      'vendor_name_HPCL', 'vendor_name_JBM Renewables', 'vendor_name_Jio-bp',\n",
    "                      'vendor_name_PlugNgo', 'vendor_name_Powerbank', 'vendor_name_Pvt. Ltd.',\n",
    "                      'vendor_name_REIL', 'vendor_name_REVOS', 'vendor_name_Smart E',\n",
    "                      'vendor_name_Sun Mobility', 'vendor_name_TPDDL', 'vendor_name_Verdemobility',\n",
    "                      'station_type_charging']\n",
    "\n",
    "# Create a preprocessor to scale numeric features and leave categorical features untouched\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply the preprocessor to your training and test data\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# You can now train your models on the scaled data\n",
    "# For example: model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "745020c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "Accuracy: 0.9538\n",
      "Precision: 0.7745\n",
      "Recall: 0.9753\n",
      "F1-Score: 0.8634\n",
      "------------------------------\n",
      "--- Decision Tree Classifier ---\n",
      "Accuracy: 0.9020\n",
      "Precision: 0.7000\n",
      "Recall: 0.6049\n",
      "F1-Score: 0.6490\n",
      "------------------------------\n",
      "--- Random Forest Classifier ---\n",
      "Accuracy: 0.9464\n",
      "Precision: 0.7766\n",
      "Recall: 0.9012\n",
      "F1-Score: 0.8343\n",
      "------------------------------\n",
      "--- K-Neighbors Classifier ---\n",
      "Accuracy: 0.9538\n",
      "Precision: 0.7917\n",
      "Recall: 0.9383\n",
      "F1-Score: 0.8588\n",
      "------------------------------\n",
      "--- AdaBoost Classifier ---\n",
      "Accuracy: 0.9593\n",
      "Precision: 0.7980\n",
      "Recall: 0.9753\n",
      "F1-Score: 0.8778\n",
      "------------------------------\n",
      "--- Gradient Boosting Classifier ---\n",
      "Accuracy: 0.9538\n",
      "Precision: 0.7917\n",
      "Recall: 0.9383\n",
      "F1-Score: 0.8588\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define a dictionary of classification models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000,random_state=42),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(random_state=42),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(random_state=42),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through each model and evaluate its performance\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate and print metrics\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f09e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final AdaBoost model has been trained on the full dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv('../data/cleaned_data.csv')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop('power_type_DC', axis=1)\n",
    "y = data['power_type_DC']\n",
    "\n",
    "# Identify numeric and categorical features (same as before)\n",
    "numeric_features = ['latitude', 'longitude', 'available', 'capacity', 'total', 'capacity_num', 'cpu_num', 'n_vehicle_types']\n",
    "categorical_features = ['supports_4w', 'supports_2w', 'vendor_name_BSES', 'vendor_name_BatterySmart',\n",
    "                      'vendor_name_BluSmart', 'vendor_name_E-Fill Electric', 'vendor_name_EEE',\n",
    "                      'vendor_name_EESL', 'vendor_name_ElectriVa', 'vendor_name_GensolCharge Pvt. Ltd.',\n",
    "                      'vendor_name_HPCL', 'vendor_name_JBM Renewables', 'vendor_name_Jio-bp',\n",
    "                      'vendor_name_PlugNgo', 'vendor_name_Powerbank', 'vendor_name_Pvt. Ltd.',\n",
    "                      'vendor_name_REIL', 'vendor_name_REVOS', 'vendor_name_Smart E',\n",
    "                      'vendor_name_Sun Mobility', 'vendor_name_TPDDL', 'vendor_name_Verdemobility',\n",
    "                      'station_type_charging']\n",
    "\n",
    "# Apply the preprocessor and scale the entire dataset\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X_scaled = preprocessor.fit_transform(X)\n",
    "\n",
    "# Train the final AdaBoost model on the entire scaled dataset\n",
    "final_model = AdaBoostClassifier(random_state=42)\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "print(\"Final AdaBoost model has been trained on the full dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c140c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/socket_prediction/artifacts/adaboost_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     os.makedirs(\u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Save the trained model to a file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodels/socket_prediction/artifacts/adaboost_model.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# It's also critical to save the preprocessor!\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# You must use the same preprocessor to transform new data before making predictions.\u001b[39;00m\n\u001b[32m     13\u001b[39m joblib.dump(preprocessor, \u001b[33m'\u001b[39m\u001b[33mmodels/preprocessor.pkl\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\numpy_pickle.py:599\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(value, filename, compress, protocol)\u001b[39m\n\u001b[32m    597\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    600\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'models/socket_prediction/artifacts/adaboost_model.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create a 'models' directory if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(final_model, 'models/socket_prediction/artifacts/adaboost_model.pkl')\n",
    "\n",
    "# It's also critical to save the preprocessor!\n",
    "# You must use the same preprocessor to transform new data before making predictions.\n",
    "joblib.dump(preprocessor, 'models/preprocessor.pkl')\n",
    "\n",
    "print(\"Model and preprocessor have been successfully saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
